input {
    kafka {
        zk_connect => "*.*.*.*:2181,*.*.*.*:2181"
        group_id => "grouplog"
        topic_id => "topiclog"
        codec => json
        consumer_threads => 1
        rebalance_max_retries => 8
        queue_size => 2048
        consumer_timeout_ms => -1
        consumer_restart_sleep_ms => 100000
        consumer_restart_on_error => true
#       decorate_events => false
#       auto_offset_reset => smallest
#       reset_beginning => false	   
  }
}

filter{
#
# --------------------access.log------
#
 if[type] =~ "log_file_access" {

  grok {
    patterns_dir => "./patterns"
    match => { "message" => "%{NGINXACCESS}"}
  }

  mutate {
    gsub => [
      "request", "\\x", "%"
#      "request_body","\\x","%"
    ]
  }


  urldecode {
    field => "request"
  }

#  urldecode {
#    field => "request_body"
#  }

}
#
# -------------------error log---------
#
else if [type] =~ "log_file_error" {
    grok {
        match => { "message" => "(?<datetime>\d\d\d\d/\d\d/\d\d \d\d:\d\d:\d\d) \[(?<errtype>\w+)\] \S+: \*\d+.*(?<clientIP>client.*%{IP})"}
    }
    grok{
       match => { "clientIP" => "(?<remote_addr>%{IP})" }
       remove_field => ["clientIP"]
   }
}

## ----------- final --do --------------
  geoip {
     source => "remote_addr"
     fields => ["city_name","location"]
  }

  mutate{
     remove_field => [ "@version" ]
  }
##--should no use  
  mutate{
    convert => ["request_time", "float"]
  }

  if ![tags]{
    mutate{
     remove_field => ["messgae"]
   }
  }
  
#  date {
#     match => ["datetime", "dd/MM/yyyy:HH:mm:ss Z","yyyy/MM/dd HH:mm:ss", "ISO8601"]
#  }

}


output {
  #stdout{codec=>rubydebug}
  elasticsearch {
    hosts => ["*.*.*.*:9200","*.*.*.*:9200"]
    #protocol => "http"
    index => "logstash-%{+YYYY.MM.dd}"
#    workers => 3
    #template_overwrite => false
  }
}
